{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "import ast\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_folder='/media/Blue2TB1/MMSys18'\n",
    "VIDEO_FOLDER=os.path.join(drive_folder,'Videos')\n",
    "VIDEO_DATA_FOLDER=os.path.join(drive_folder,'video_data')\n",
    "OUTPUT_TRUE_SALIENCY_FOLDER = os.path.join(drive_folder,'true_saliency')\n",
    "VIDEO_IMG_PATH=os.path.join(drive_folder,'5fps_Video_Images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_lens={}\n",
    "videos=os.listdir(VIDEO_IMG_PATH)\n",
    "for video in videos:\n",
    "    tstamps=np.load(os.path.join(VIDEO_IMG_PATH,video,'timestamps.npy'))\n",
    "    vid_lens[video]=len(tstamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n",
      "(100,)\n"
     ]
    }
   ],
   "source": [
    "for video in videos:\n",
    "    uvs=np.load(os.path.join(VIDEO_DATA_FOLDER,video,f'{video}_unit_vectors.npy'))\n",
    "    tstamps=np.load(os.path.join(VIDEO_DATA_FOLDER,video,f'{video}_timestamps.npy'))\n",
    "    SI_path=os.path.join(VIDEO_DATA_FOLDER,video,f'{video}_SI.npy')\n",
    "    TI_path=os.path.join(VIDEO_DATA_FOLDER,video,f'{video}_TI.npy')\n",
    "    TIs=np.load(TI_path)\n",
    "    SIs=np.load(SI_path)\n",
    "    #np.save(SI_path,SIs[:100])\n",
    "    #np.save(TI_path,TIs[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capturing video frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_frames(video_path,output_folder,fps=None,rescale=2):\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    #print(f\"Saving video {os.path.basename(video_path).split('.')[0]}\")\n",
    "    video=cv2.VideoCapture(os.path.join(video_path))\n",
    "    original_frame_rate=round(video.get(cv2.CAP_PROP_FPS))\n",
    "    print(original_frame_rate)\n",
    "    is_div= original_frame_rate%fps==0\n",
    "    #vid_num=os.path.basename(video_path).split('.')[0]\n",
    "    #trajectory_folder=os.path.join(\"D:/CVPR18/sampled_dataset\",vid_num)\n",
    "    #files = os.listdir(trajectory_folder)\n",
    "    #first_file = os.path.join(trajectory_folder, files[0])\n",
    "    #data = pd.read_csv(first_file, header=None) \n",
    "    #print(len(data))\n",
    "    \n",
    "    #print(is_div)\n",
    "    original_frame_width=int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_frame_height=int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_duration=1/original_frame_rate\n",
    "    #desired_timestamps = np.arange(0, int(video.get(cv2.CAP_PROP_FRAME_COUNT)) /original_frame_rate, 0.2)\n",
    "    #print(desired_timestamps[-1]\n",
    "    if fps:\n",
    "        frame_interval=original_frame_rate//fps\n",
    "    else:\n",
    "        frame_interval=1\n",
    "    frame_count=0\n",
    "    last_frame=int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    #print(frame_duration*last_frame)\n",
    "    timestamps=[]\n",
    "    frames=[]\n",
    "    while video.isOpened():\n",
    "        ret,frame=video.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if is_div:\n",
    "            if frame_count%frame_interval==0 or frame_count+1==last_frame:\n",
    "                frame=cv2.resize(frame,(original_frame_width//rescale,original_frame_height//rescale))\n",
    "                frames.append(frame)\n",
    "                timestamps.append(frame_count*frame_duration)\n",
    "            #print((frame_count)*frame_duration)\n",
    "        else:\n",
    "            frame=cv2.resize(frame,(original_frame_width//rescale,original_frame_height//rescale))\n",
    "            frames.append(frame)\n",
    "            timestamps.append(frame_count*frame_duration)\n",
    "        frame_count+=1\n",
    "    #print(frame_count)\n",
    "    if not is_div:\n",
    "        sampled_frames=[]\n",
    "        sampled_timestamps=[]\n",
    "        desired_timestamps=list(np.arange(0,round(timestamps[-1])+0.1,1/fps))\n",
    "        for ts in desired_timestamps:\n",
    "            closest_idx=np.abs(timestamps-ts).argmin()\n",
    "            sampled_frames.append(frames[closest_idx])\n",
    "            sampled_timestamps.append(timestamps[closest_idx])\n",
    "        timestamps=sampled_timestamps\n",
    "        frames=sampled_frames\n",
    "    #print(len(timestamps))\n",
    "    #if len(data)!=len(timestamps):\n",
    "    #    print(vid_num)\n",
    "    #print(desired_timestamps)\n",
    "    video.release()\n",
    "    #for i,frame in enumerate(frames):\n",
    "        #np.save(f'{output_folder}/{i}.npy',frame)\n",
    "    np.save(f'{output_folder}/sampled_video.npy',frames)\n",
    "    np.save(f'{output_folder}/timestamps.npy',timestamps)\n",
    "    \n",
    "    #print(f\"Saved video {video_path[-6:-3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder=\"D:/Jin_22\"\n",
    "video_folder=os.path.join(dataset_folder,'Videos')\n",
    "videos=[d.split('.')[0] for d in os.listdir(video_folder) if os.path.isfile(os.path.join(video_folder,d))]\n",
    "#videos=sorted(videos,key=lambda x:int(x.split('_')[1]))\n",
    "sample_videos=False\n",
    "output_dir=video_folder\n",
    "ct=0\n",
    "output_dir=os.path.join(dataset_folder,\"5fps_Video_Images\")\n",
    "if sample_videos:    \n",
    "    for video in videos:\n",
    "        video_path=os.path.join(video_folder,video+\".mp4\")\n",
    "        #video_path=os.path.join(video_folder,\"video_1.mp4\")\n",
    "        output_folder=os.path.join(output_dir,video)\n",
    "        store_frames(video_path,output_folder, fps=5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling User Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_folder=os.path.join(dataset_folder,\"Version2\")\n",
    "video_img_folder=os.path.join(dataset_folder,'5fps_Video_Images')\n",
    "user_folder=os.path.join(users_folder,'V2 (1)')\n",
    "trajec_dir=os.path.join(dataset_folder,'Full_Dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rearrange_folders(base_dir,dest_dir):\n",
    "    user_folders=sorted(os.listdir(base_dir),key=lambda x:int(x.split(' ')[1][1:-1]))\n",
    "    for folder in user_folders:\n",
    "        user_num=folder.split(' ')[1][1:-1]\n",
    "        user_folder_path=os.path.join(base_dir,folder)\n",
    "        trajectory_files=os.listdir(os.path.join(user_folder_path))\n",
    "        for trajectory_file in trajectory_files:\n",
    "            vid_num=trajectory_file.split('_')[2]\n",
    "            new_name=f'user-{user_num}_vid-{vid_num}_trajectory.csv'\n",
    "            vid_folder_path=os.path.join(dest_dir,f'video_{vid_num}')\n",
    "            if not os.path.exists(vid_folder_path):\n",
    "                os.makedirs(vid_folder_path)\n",
    "            \n",
    "            src_path=os.path.join(user_folder_path,trajectory_file)\n",
    "            dst_path=os.path.join(vid_folder_path,new_name)\n",
    "            shutil.copy2(src_path,dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearrange_folders(users_folder,trajec_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_position(timestamps,positions,new_timestamps):\n",
    "    interp_fun=interp1d(timestamps,positions,axis=0,kind='linear',fill_value='extrapolate')\n",
    "    return interp_fun(new_timestamps)\n",
    "\n",
    "def interpolate_quat(timestamps,quaternions,new_timestamps):\n",
    "    slerp=R.from_quat(quaternions)\n",
    "    key_rots=slerp.as_quat()\n",
    "    interp_fun=interp1d(timestamps,key_rots,axis=0,kind='linear', fill_value='extrapolate')\n",
    "    interpolated_rots=interp_fun(new_timestamps)\n",
    "    return R.from_quat(interpolated_rots).as_quat()\n",
    "\n",
    "def interpolate_unit_vector(timestamps, vectors, new_timestamps):\n",
    "    interp_func = interp1d(timestamps, vectors, axis=0, kind='linear', fill_value='extrapolate')\n",
    "    interpolated_vectors = interp_func(new_timestamps)\n",
    "    norm = np.linalg.norm(interpolated_vectors, axis=1, keepdims=True)\n",
    "    normalized_vectors = interpolated_vectors / norm\n",
    "    return normalized_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_timestamps(video_folder):\n",
    "    video_timestamps={}\n",
    "    for root,dirs,files in os.walk(video_folder):\n",
    "        for dir in dirs:\n",
    "            video_number=int(dir.split('_')[1])\n",
    "            timestamps_path=os.path.join(root,dir,'timestamps.npy')\n",
    "            if os.path.exists(timestamps_path):\n",
    "                video_timestamps[video_number]=np.load(timestamps_path)\n",
    "    return video_timestamps\n",
    "\n",
    "def get_video_number(file_name):\n",
    "    vid_number=int(file_name.split('_')[2])\n",
    "    return vid_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(file_path, new_timestamps):\n",
    "    #print(file_path)\n",
    "    data=pd.read_csv(file_path)\n",
    "    time=data['AdjustedTime']\n",
    "    #print(time[0])\n",
    "    time=time-time[0]\n",
    "    #print(time[0])\n",
    "    pose_position=np.array(data['Pose_Position'].apply(ast.literal_eval).tolist())\n",
    "    pose_rotation=np.array(data['Pose_Rotation'].apply(ast.literal_eval).tolist())\n",
    "    unit_vector=np.array(data['Unit_Vector'].apply(ast.literal_eval).tolist())\n",
    "    #print(pose_position)\n",
    "    #print(pose_rotation[23,:],pose_rotation[24,:],pose_rotation[25,:])\n",
    "    #print(len(time))\n",
    "    #print(len(pose_rotation))\n",
    "    interpolated_position=interpolate_position(time,pose_position,new_timestamps)\n",
    "    interpolated_rotation=interpolate_quat(time,pose_rotation,new_timestamps)\n",
    "    interpolated_unit_vector=interpolate_unit_vector(time,unit_vector,new_timestamps)\n",
    "    #print(interpolated_position.tolist())\n",
    "    #print(interpolated_position[1,:])\n",
    "    \"\"\" sampled_data = pd.DataFrame({\n",
    "        'Timestamp': new_timestamps,\n",
    "        'Pose_Position': interpolated_position.tolist(),\n",
    "        'Pose_Rotation': interpolated_rotation.tolist(),\n",
    "        'Unit_Vector': interpolated_unit_vector.tolist(),\n",
    "    }) \"\"\"\n",
    "    \n",
    "    return interpolated_position,interpolated_rotation,interpolated_unit_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_numpy_arrays(video_output_dir, vid_name, user_data):\n",
    "    timestamps, users, positions, rotations, vectors = user_data\n",
    "    np.save(os.path.join(video_output_dir, f\"{vid_name}_users.npy\"), users)\n",
    "    np.save(os.path.join(video_output_dir, f\"{vid_name}_timestamps.npy\"), timestamps)\n",
    "    np.save(os.path.join(video_output_dir, f\"{vid_name}_positions.npy\"), positions)\n",
    "    np.save(os.path.join(video_output_dir, f\"{vid_name}_rotations.npy\"), rotations)\n",
    "    np.save(os.path.join(video_output_dir, f\"{vid_name}_unit_vectors.npy\"), vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder='D:/Jin_22'\n",
    "trajec_dir=os.path.join(dataset_folder,'Full_Dataset')\n",
    "users_folder=os.path.join(dataset_folder,\"Version2\")\n",
    "video_img_folder=os.path.join(dataset_folder,'5fps_Video_Images')\n",
    "video_path=os.path.join(dataset_folder,'Videos')\n",
    "agg_folder=os.path.join(dataset_folder,'Trajectory_info')\n",
    "sampled_trajectories=os.path.join(dataset_folder,'sampled_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstamps=load_timestamps(video_img_folder)\n",
    "output_dir=\"D:/Jin_22/Trajectory_info\"\n",
    "videos=os.listdir(trajec_dir)\n",
    "def resample_trajectories(src_dir,dst_dir,video_img_folder):\n",
    "    tstamps=load_timestamps(video_img_folder)\n",
    "    videos=os.listdir(src_dir)\n",
    "    for vid in videos:\n",
    "        vid_path=os.path.join(src_dir,vid)\n",
    "        vid_num=vid.split(\"_\")[1]\n",
    "        timestamps=tstamps[int(vid_num)]\n",
    "        output_dir=os.path.join(dst_dir,vid)\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        csv_files=[f for f in os.listdir(vid_path) if f.endswith('.csv')]\n",
    "        for f in csv_files:\n",
    "            traj_path=os.path.join(vid_path,f)\n",
    "            pos,rots,unit_vecs=process_csv(traj_path,timestamps)\n",
    "            sampled_data=pd.DataFrame({\n",
    "                'Timestamp':timestamps,\n",
    "                'Pose_Position': pos.tolist(),\n",
    "                'Pose_Rotation': rots.tolist(),\n",
    "                'Unit_Vector':unit_vecs.tolist()\n",
    "            })\n",
    "            dst_path=os.path.join(dst_dir,vid)\n",
    "            sampled_data.to_csv(dst_path,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resample_trajectories(trajec_dir,sampled_trajectories,video_img_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_num(filename):\n",
    "    num=filename.split('_')[0].split('-')[1]\n",
    "    return int(num)\n",
    "\n",
    "def get_user_list(traj_names):\n",
    "    user_names=[]\n",
    "    for traj_name in traj_names:\n",
    "        user_name=traj_name.split('_')[0]\n",
    "        user_names.append(user_name)\n",
    "    return user_names\n",
    "\n",
    "def store_trajectory_aggregates(src_dir,dst_dir):\n",
    "    videos=os.listdir(src_dir)\n",
    "    print(len(videos))\n",
    "    for video in videos:\n",
    "        trajs=os.listdir(os.path.join(src_dir,video))\n",
    "        print(f'Processing {video}')\n",
    "        op_dir=os.path.join(dst_dir,video)\n",
    "        if not os.path.exists(op_dir):\n",
    "            os.makedirs(op_dir)\n",
    "        poses=[]\n",
    "        rots=[]\n",
    "        uvs=[]\n",
    "        trajs=sorted(trajs,key=get_user_num)\n",
    "        users=get_user_list(trajs)\n",
    "        for traj in trajs:\n",
    "            path=os.path.join(src_dir,video,traj)\n",
    "            df=pd.read_csv(path)\n",
    "            tstamps=np.array(df['Timestamp'])\n",
    "            pos=np.array(df['Pose_Position'].apply(ast.literal_eval).tolist())\n",
    "            rot=np.array(df['Pose_Rotation'].apply(ast.literal_eval).tolist())\n",
    "            uv=np.array(df['Unit_Vector'].apply(ast.literal_eval).tolist())\n",
    "            poses.append(pos)\n",
    "            rots.append(rot)\n",
    "            uvs.append(uv)\n",
    "        uvs=np.array(uvs)\n",
    "        poses=np.array(poses)\n",
    "        rots=np.array(rots)\n",
    "\n",
    "        save_numpy_arrays(op_dir,video,(tstamps,users,poses,rots,uvs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "Processing video_10\n",
      "Processing video_11\n",
      "Processing video_12\n",
      "Processing video_13\n",
      "Processing video_14\n",
      "Processing video_15\n",
      "Processing video_16\n",
      "Processing video_17\n",
      "Processing video_18\n",
      "Processing video_19\n",
      "Processing video_1\n",
      "Processing video_20\n",
      "Processing video_21\n",
      "Processing video_22\n",
      "Processing video_23\n",
      "Processing video_24\n",
      "Processing video_25\n",
      "Processing video_26\n",
      "Processing video_27\n",
      "Processing video_2\n",
      "Processing video_3\n",
      "Processing video_4\n",
      "Processing video_5\n",
      "Processing video_6\n",
      "Processing video_7\n",
      "Processing video_8\n",
      "Processing video_9\n"
     ]
    }
   ],
   "source": [
    "store_trajectory_aggregates(sampled_trajectories,agg_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2=np.load('D:/Jin_22/Trajectory_info/Video_7/Video_7_rotations.npy')\n",
    "test=np.load('D:/Jin_22/Trajectory_info/Video_10/Video_10_rotations.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CVPR18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder='D:/CVPR18'\n",
    "sampled_dataset=os.path.join(dataset_folder,'sampled_dataset')\n",
    "trajec_dir=os.path.join(dataset_folder,'Trajectory_info')\n",
    "video_folder=os.path.join(dataset_folder,'Videos')\n",
    "\n",
    "def get_user_num(filename):\n",
    "    user_num=int(filename[1:])\n",
    "    return user_num\n",
    "\n",
    "def store_numpy(src_dir,dst_dir):\n",
    "    videos=os.listdir(src_dir)\n",
    "    for video in videos:\n",
    "        vid_path=os.path.join(src_dir,video)\n",
    "        users=os.listdir(vid_path)\n",
    "        dst_path=os.path.join(dst_dir,video)\n",
    "        #print(video)\n",
    "        if not os.path.exists(dst_path):\n",
    "            os.makedirs(dst_path)\n",
    "        uvs=[]\n",
    "        tstamps=[]\n",
    "        users=sorted(users,key=get_user_num)\n",
    "        for user in users:\n",
    "            traj_path=os.path.join(vid_path,user)\n",
    "            traj=np.loadtxt(traj_path,delimiter=',')\n",
    "            #print(traj.shape)\n",
    "            tstamps=traj[:,0]\n",
    "            uv=traj[:,1:]\n",
    "            #print(uv.shape)\n",
    "            uvs.append(uv)\n",
    "        shortest=len(min(uvs,key=len))\n",
    "        longest=len(max(uvs,key=len))\n",
    "        if shortest!=longest:\n",
    "            print(f'{video}: {longest-shortest} : {longest}')\n",
    "            prob=np.array([True,shortest,longest])\n",
    "            np.save(os.path.join(dst_path,f'{video}_len_correction.npy'),prob)\n",
    "        uvs=np.array([uv[:shortest] for uv in uvs])\n",
    "        np.save(os.path.join(dst_path,f'{video}_timestamps.npy'),tstamps)\n",
    "        np.save(os.path.join(dst_path,f'{video}_unit_vectors.npy'),uvs)\n",
    "        np.save(os.path.join(dst_path,f'{video}_users.npy'),np.array(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "006: 1 : 293\n",
      "059: 1 : 163\n",
      "066: 1 : 155\n",
      "070: 6 : 108\n",
      "074: 1 : 238\n",
      "087: 1 : 125\n",
      "090: 1 : 108\n",
      "094: 18 : 108\n",
      "098: 1 : 105\n",
      "102: 1 : 124\n",
      "118: 1 : 196\n",
      "119: 5 : 173\n",
      "120: 12 : 290\n",
      "121: 5 : 196\n",
      "123: 1 : 169\n",
      "124: 2 : 77\n",
      "125: 2 : 196\n",
      "127: 1 : 237\n",
      "128: 3 : 295\n",
      "129: 1 : 234\n",
      "131: 1 : 203\n",
      "132: 33 : 259\n",
      "133: 49 : 196\n",
      "134: 42 : 167\n",
      "135: 16 : 161\n",
      "137: 5 : 134\n",
      "138: 1 : 183\n",
      "139: 1 : 193\n",
      "140: 7 : 141\n",
      "142: 2 : 199\n",
      "153: 9 : 243\n",
      "159: 1 : 158\n",
      "166: 8 : 108\n",
      "167: 1 : 144\n",
      "169: 3 : 194\n",
      "171: 13 : 204\n",
      "172: 4 : 256\n",
      "174: 3 : 219\n",
      "175: 2 : 229\n",
      "176: 27 : 256\n",
      "177: 24 : 169\n",
      "187: 1 : 203\n",
      "189: 3 : 182\n",
      "198: 1 : 217\n",
      "203: 1 : 247\n",
      "204: 1 : 221\n",
      "211: 1 : 146\n",
      "212: 1 : 267\n",
      "213: 2 : 151\n",
      "214: 2 : 152\n",
      "215: 3 : 173\n"
     ]
    }
   ],
   "source": [
    "store_numpy(sampled_dataset,trajec_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOSSDAV_17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder='D:/Fan_NOSSDAV_17'\n",
    "sampled_dataset=os.path.join(dataset_folder,'sampled_dataset')\n",
    "trajec_dir=os.path.join(dataset_folder,'Trajectory_info')\n",
    "video_folder=os.path.join(dataset_folder,'Videos')\n",
    "\n",
    "def get_user_num(filename):\n",
    "    user_num=int(filename[-2:])\n",
    "    return user_num\n",
    "\n",
    "def store_numpy(src_dir,dst_dir):\n",
    "    videos=os.listdir(src_dir)\n",
    "    for video in videos:\n",
    "        vid_path=os.path.join(src_dir,video)\n",
    "        users=os.listdir(vid_path)\n",
    "        dst_path=os.path.join(dst_dir,video)\n",
    "        #print(video)\n",
    "        if not os.path.exists(dst_path):\n",
    "            os.makedirs(dst_path)\n",
    "        uvs=[]\n",
    "        tstamps=[]\n",
    "        users=sorted(users,key=get_user_num)\n",
    "        for user in users:\n",
    "            traj_path=os.path.join(vid_path,user)\n",
    "            traj=np.loadtxt(traj_path,delimiter=',')\n",
    "            #print(traj.shape)\n",
    "            tstamps=traj[:,0]\n",
    "            uv=traj[:,1:]\n",
    "            #print(uv.shape)\n",
    "            uvs.append(uv)\n",
    "        \n",
    "        shortest=len(min(uvs,key=len))\n",
    "        longest=len(max(uvs,key=len))\n",
    "        if shortest!=longest:\n",
    "            print(f'{video}: {longest-shortest} : {longest}')\n",
    "            prob=np.array([True,shortest,longest])\n",
    "            np.save(os.path.join(dst_path,f'{video}_len_correction.npy'),prob)\n",
    "        uvs=np.array([uv[:shortest] for uv in uvs])\n",
    "        np.save(os.path.join(dst_path,f'{video}_timestamps.npy'),tstamps)\n",
    "        np.save(os.path.join(dst_path,f'{video}_unit_vectors.npy'),uvs)\n",
    "        np.save(os.path.join(dst_path,f'{video}_users.npy'),np.array(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_numpy(sampled_dataset,trajec_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PAMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder='D:/PAMI18'\n",
    "sampled_dataset=os.path.join(dataset_folder,'sampled_dataset')\n",
    "trajec_dir=os.path.join(dataset_folder,'video_data')\n",
    "video_folder=os.path.join(dataset_folder,'Videos')\n",
    "\n",
    "def get_user_num(filename):\n",
    "    user_num=int(filename[-2:])\n",
    "    return user_num\n",
    "\n",
    "def store_numpy(src_dir,dst_dir):\n",
    "    videos=os.listdir(src_dir)\n",
    "    for video in videos:\n",
    "        \n",
    "        vid_path=os.path.join(src_dir,video)\n",
    "        users=os.listdir(vid_path)\n",
    "        dst_path=os.path.join(dst_dir,video)\n",
    "        #print(video)\n",
    "        if not os.path.exists(dst_path):\n",
    "            os.makedirs(dst_path)\n",
    "        uvs=[]\n",
    "        tstamps=[]\n",
    "        users=sorted(users)\n",
    "        for user in users:\n",
    "            traj_path=os.path.join(vid_path,user)\n",
    "            traj=np.loadtxt(traj_path,delimiter=',')\n",
    "            #print(traj.shape)\n",
    "            tstamps=traj[:,0]\n",
    "            uv=traj[:,1:]\n",
    "            #print(uv.shape)\n",
    "            uvs.append(uv)\n",
    "        \n",
    "        shortest=len(min(uvs,key=len))\n",
    "        longest=len(max(uvs,key=len))\n",
    "        if shortest!=longest:\n",
    "            print(f'{video}: {longest-shortest} : {longest}')\n",
    "            prob=np.array([True,shortest,longest])\n",
    "            np.save(os.path.join(dst_path,f'{video}_len_correction.npy'),prob)\n",
    "        uvs=np.array([uv[:shortest] for uv in uvs])\n",
    "        np.save(os.path.join(dst_path,f'{video}_timestamps.npy'),tstamps)\n",
    "        np.save(os.path.join(dst_path,f'{video}_unit_vectors.npy'),uvs)\n",
    "        np.save(os.path.join(dst_path,f'{video}_users.npy'),np.array(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waterfall: 1 : 102\n"
     ]
    }
   ],
   "source": [
    "store_numpy(sampled_dataset,trajec_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MMSys18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder='D:/MMSys18'\n",
    "sampled_dataset=os.path.join(dataset_folder,'sampled_dataset')\n",
    "trajec_dir=os.path.join(dataset_folder,'video_data')\n",
    "video_folder=os.path.join(dataset_folder,'Videos')\n",
    "\n",
    "def get_user_num(filename):\n",
    "    user_num=int(filename)\n",
    "    return user_num\n",
    "\n",
    "def store_numpy(src_dir,dst_dir):\n",
    "    videos=os.listdir(src_dir)\n",
    "    videos=[vid for vid in videos if os.path.isdir(os.path.join(src_dir,vid))]\n",
    "    for video in videos:\n",
    "        \n",
    "        vid_path=os.path.join(src_dir,video)\n",
    "        users=os.listdir(vid_path)\n",
    "        dst_path=os.path.join(dst_dir,video)\n",
    "        print(f'Processing {video}')\n",
    "        if not os.path.exists(dst_path):\n",
    "            os.makedirs(dst_path)\n",
    "        uvs=[]\n",
    "        tstamps=[]\n",
    "        users=sorted(users,key=get_user_num)\n",
    "        for user in users:\n",
    "            traj_path=os.path.join(vid_path,user)\n",
    "            traj=np.loadtxt(traj_path,delimiter=',')\n",
    "            #print(traj.shape)\n",
    "            tstamps=traj[:,0]\n",
    "            uv=traj[:,1:]\n",
    "            #print(uv.shape)\n",
    "            uvs.append(uv)\n",
    "        \n",
    "        shortest=len(min(uvs,key=len))\n",
    "        longest=len(max(uvs,key=len))\n",
    "        if shortest!=longest:\n",
    "            print(f'{video}: {longest-shortest} : {longest}')\n",
    "            prob=np.array([True,shortest,longest])\n",
    "            np.save(os.path.join(dst_path,f'{video}_len_correction.npy'),prob)\n",
    "        uvs=np.array([uv[:shortest] for uv in uvs])\n",
    "        np.save(os.path.join(dst_path,f'{video}_timestamps.npy'),tstamps)\n",
    "        np.save(os.path.join(dst_path,f'{video}_unit_vectors.npy'),uvs)\n",
    "        np.save(os.path.join(dst_path,f'{video}_users.npy'),np.array(users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10_Cows\n",
      "Processing 11_Abbottsford\n",
      "Processing 12_TeatroRegioTorino\n",
      "Processing 13_Fountain\n",
      "Processing 14_Warship\n",
      "Processing 15_Cockpit\n",
      "Processing 16_Turtle\n",
      "Processing 17_UnderwaterPark\n",
      "Processing 18_Bar\n",
      "Processing 19_Touvet\n",
      "Processing 1_PortoRiverside\n",
      "Processing 2_Diner\n",
      "Processing 3_PlanEnergyBioLab\n",
      "Processing 4_Ocean\n",
      "Processing 5_Waterpark\n",
      "Processing 6_DroneFlight\n",
      "Processing 7_GazaFishermen\n",
      "Processing 8_Sofa\n",
      "Processing 9_MattSwift\n"
     ]
    }
   ],
   "source": [
    "store_numpy(sampled_dataset,trajec_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
